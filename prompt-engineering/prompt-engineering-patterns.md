| #  | Category             | Pattern                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Example                                                                                                                                                                                                                                                                                                                  | Pros                                                                                                                                                                                                                                                                                       | Cons                                                                                                                                                                                                                                      |
| -- | -------------------- | ---------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1  | Input Semantics      | Meta language creation pattern           | An alternative language  or short hand notation that should be explained to the LLM.<br>Motivation: This is helpful when it is difficult to convert some information in English. Less words<br>                                                                                                                                                                                                                                                                                                                                          | From now when I say carrots:2, tomatoes:3 I mean carrots 2 kgs                                                                                                                                                                                                                                                           | Precise, short                                                                                                                                                                                                                                                                             | Can create ambiquity if the language is not correctly defined. However, chatgpt will warn if the reference is too ambiguious                                                                                                              |
| 2  | Output customization | Output automator pattern                 | Makes the LLM generate an automation artifact that when applied executes the same set of the actions it is asking the user to do.                                                                                                                                                                                                                                                                                                                                                                                                        | Produce a python script to split a large file into chunks of 1 MB with a summary.<br>From now on when ever you generate code that spans across multiple files, generate a python script to genertae the files or update existing files.                                                                                  | Using chatgpt models for easily integrating the code generated (like copilot) since copilot cannot generate entire files.<br>Generating command line scripts, DevOps.<br>Integrtaes chatgpt into applictaions that are programmable.<br>Works well when entire context is in a single line | Needs more contextual information to generate automation artifacts, works well in conversation stylle of communictaion<br>LLMs can produce inaccurate results so it carries significant risk of the output is applied without inspection. |
| 3  | Interaction          | Flipped Interaction Pattern              | Invert the conversation flow by allowing LLM To ask questions until a specific goal or a condition is met. Additionally we can ask LLM to ask one or more than one questions at a time. The prompt should be more precise for the LLM to narrow down the scope of questions. LLM can also make choices for certain questions                                                                                                                                                                                                             | From now on I would like you to ask questions to create an azure function to create thumbnails when an image is uploaded to azure storage account. When you have enough information create a powershell script to automate the deployment.                                                                               | LLM can choose better questions specific to the tas                                                                                                                                                                                                                                        | The conversation may become open ended if the exit criteria is not clearly mentioned in the prompt.<br>The choices made should be made explicit so that the user is aware what decisions are taken based on conversation                  |
| 4  | Output customization | Persona Pattern                          | Give LLM a persona, ask LLM to generate output as generated by a specific persona.<br>The persona can be non-human like terminal, animal,                                                                                                                                                                                                                                                                                                                                                                                                | Conduct code review acting as a security specialist and provide comments a security reviewer.<br>"Situation awareness": act as a linux terminal that is attacked and compromized by a hacker                                                                                                                             |                                                                                                                                                                                                                                                                                            | More chances for LLM to hallucinate or assume                                                                                                                                                                                             |
| 5  | Prompt Improvement   | The question refinement pattern          | Asks the LLM to provide a better version of the question. LLM can help achieve the goal of the user in fewer interactions. This can be combined with reflection pattern to know why LLM things its version is better than the original ask.This can be combined with cognitive verifier pattern to reduce the risk of narrow down. Example: "“Fromnowon,wheneverIaskaquestion,askfour additionalquestionsthatwouldhelpyouproducea betterversionofmyoriginalquestion.Then,usemy answerstosuggestabetterversionofmyoriginal question."<br> | From now on what I ask you a question on important security practices while write code, suggest a better version of the question that allows me to handle important security threats.                                                                                                                                    | Improves efficiency and accuracy.                                                                                                                                                                                                                                                          | Risk of narrowing down the question to a limited path. May introduce unfamiliar terms to the user. (this can be combined with persona pattern to explain unfamilar terms)                                                                 |
| 6  | Prompt Improvement   | The alternative approaches pattern       | LLM teachs alternative approaches to accomplish a task. Additionally you can ask for pros and cons and which alternative is best suited.                                                                                                                                                                                                                                                                                                                                                                                                 | Whenever I ask you to deploy an application to azure, provide me with alternatives to accomplish the task, list the best alternatives and compare the pros and cons of each approach with respect to security, cost and scalability and include the original way I asked. Then prompt me which alternative I should pick | Efficient, can be applied to range of tasks. Provide domain specific approved set of alternatives                                                                                                                                                                                          |                                                                                                                                                                                                                                           |
| 7  | Prompt Improvement   | The cognitive verifier pattern           | LLMs can be taught to divide the question into multiple subquestions. Answer each subquestion and then combine the answers of each question into a final answer. This is because LLMs are at best when the the question is divided into multiple subquestions                                                                                                                                                                                                                                                                            | when I ask you a question generate 3 additional questions that would help you give more accurate answer. When I answer the questions combine the answers to provide a  final answer to my question                                                                                                                       | Improves efficiency and accuracy. Encourages critical thinking to the user, new insights. User is forced to provide only the information related to the questions reducing the amount of information exchange.<br>                                                                         | LLM may ask scope out some questions if exact count is asked, the scoped out question could be relevant to the user.                                                                                                                      |
| 8  | Error identification | The fact checklist pattern               | Ask LLM to provide a list of facts after the output so that the user can cross verify                                                                                                                                                                                                                                                                                                                                                                                                                                                    | from now on when ever you generate a answer create a set of facts that the answer depends on and those that should be fact checked. Include the facts at the end of the output. Include facts only related to cyber security/                                                                                            | This pattern can be combined with variety of patterns because fact check is essential in any LLM use case.                                                                                                                                                                                 | It can oonly be applied to certain output types, for example in code generation the LLM cannot do a fact check even though the output may contain errors.                                                                                 |
| 9  | Output customization | The template pattern                     | Instructs the LLM to use a specific pattern for output                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | im going to provide a template, everything within angular brackets is a template when ever you generate a response try to fit in the placeholders. Please preserve the formatting of the template. The template is http://api/products/{PRODUCT}/quantity/{quantity}                                                     | Helps in automation tasks.                                                                                                                                                                                                                                                                 | The LLMs output that may be helpful to the user may get eliminated. Hard to combine with other patterns                                                                                                                                   |
| 10 | Interaction          | The infinite generation pattern          | This pattern asks the LLM to generate a series of outputs restricted by a predefined number of explicit instructions from the user. This is useful in repeatitive outputs applied to various contexts. The series of outputs can be influenced by more variations of input from the user that is applied to orginal prompt.                                                                                                                                                                                                              | From now until I say stop generate a english proverb about knowledge and learning                                                                                                                                                                                                                                        | Can be combine with template pattern to generate a similar looking templated output. Ex: SQL statements for different entities but same schema                                                                                                                                             | The input to the LLM is previous conversations and current prompt for such infinite response the model may forget (memory limitations) the original ask and deviate.                                                                      |
| 11 | Output customization | The visualization generalization pattern | This pattern asks the LLM to respond in a way that allows to draw a diagram from the output.                                                                                                                                                                                                                                                                                                                                                                                                                                             | generic : when I ask you visualize, create a graphviz or dall-e prompt that can be used to create the visualization.<br>"Given the data apples 2, oranges 19, grapes 15 create a graphviz visualization"                                                                                                                 | Better communication combining the strengths of text and visualization.<br>LLM can select the appropriate visualization for the given the data.                                                                                                                                            |                                                                                                                                                                                                                                           |
| 12 | Interaction          | The gameplay pattern                     | Generates a game around a given topic. Can be combined with output customization pattern to generate images. This can be used when scope of game rules is limited but content is wider.                                                                                                                                                                                                                                                                                                                                                  | From now we are going to play a game around reinforcment learning. Some rules of the game are if I answer the question right add 10 points to total score, if I answer the question wrong deduct-5 points from total score. Generate multiple choice questions for the topic and stop when I say stop.                   | Can be combined with other patterns to create interactive gaming applications specially when rules are limited and content scope is wider.                                                                                                                                                 | works only for limited set of rules. Rules can get ambigious leading to incorrect application.                                                                                                                                            |
| 13 | Error identification | The reflection pattern                   | This pattern asks the LLM to provide the rationale, reasoning and assumptions behind the response.                                                                                                                                                                                                                                                                                                                                                                                                                                       | From now one when you generate the response provide the reasoning and assumptions made to arrive at the response so that I can improve the question                                                                                                                                                                      | LLMs can make mistake or hallucinate this helps in identifying the reasoning behind certain responses.<br>This can be combined with fact check pattern to identify facts based on which the response is generated.<br>Can be used for debugging LLM's response                             | The reasoning behind the response may not be understandable if you do not have enough knowledge on the topic.<br>Like the initial response even the reasoning can have errors.                                                            |
| 14 | Prompt Improvement   | The refusal breaker pattern              | this patterns allows users to break the resistence from LLM in answering a query. The refusal could  be due to incorrect question, incorrect wordings. LLMs helps to rephrase or reword certain parts of the question.                                                                                                                                                                                                                                                                                                                   | whenever you cannot answer a question, explain why you cannot answer and provide alternatives on how to rephrase or reword to improve the question                                                                                                                                                                       | retrospectively identify the right framing or wordings in the question and frame it in a more understandable way.                                                                                                                                                                          | It can be easily misused.<br>The alternatives presented may not be semantically same as the original question.                                                                                                                            |
| 15 | Context control      | The contextual manager pattern           | This pattern allows the user to add/remove context from the conversation                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | from now on when you are generating the answer consider the scope as within India only                                                                                                                                                                                                                                   | greater control. More accurate response. It can be used to erase the entire history of conversations and start over. (reset)                                                                                                                                                               | may unknowingly override org. rules if applied or older contexts which are imp.                                                                                                                                                           |
| 16 | Output customization | The receipe pattern                      | This pattern asks the LLM to respond using a sequence of steps using ingredients & goal presented by the user.                                                                                                                                                                                                                                                                                                                                                                                                                           | explain using a sequence of steps how to make a best protein snack using ingredients like paneer, corn, milk. Remove any unnecessary steps and add any missing steps.                                                                                                                                                    | it is helpful when you know the end goal and few ingredients but do not know the sequence of steps.<br>Helpful in problems which need an Ordered approach to solution                                                                                                                      | the user may not be able to describe the goal precisely.<br>It may introduce unwanted bias to the ingredients even though there could be a better solution.                                                                               |