{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import langchain\n",
    "import matplotlib as plt\n",
    "from langchain import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain import OpenAI, SQLDatabase\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.chains import LLMMathChain, LLMChain, RetrievalQA, SequentialChain, TransformChain\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "OPENAI_EMBEDDING_VERSION = os.getenv(\"OPENAI_EMBEDDING_VERSION\")\n",
    "\n",
    "#init Azure OpenAI\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿namespace CDMS.CP.PlatForm.Core.Common.CoreFunctionHelpers.API.Helpers\n",
      "{\n",
      "    using System;\n",
      "    using System.Collections.Generic;\n",
      "    using System.ComponentModel.DataAnnotations;\n",
      "    using System.Diagnostics.CodeAnalysis;\n",
      "    using System.Globalization;\n",
      "    using System.Linq;\n",
      "    using System.Reflection;\n",
      "    using System.Security.Claims;\n",
      "    using CDMS.CP.Platform.Common.Logging.V2.Interfaces;\n",
      "    using Newtonsoft.Json;\n",
      "    using Validation;\n",
      "\n",
      "    /// <summary>\n",
      "    /// Common Helper.\n",
      "    /// </summary>\n",
      "    public static class CommonHelpers\n",
      "    {\n",
      "        /// <summary>\n",
      "        /// Returns the validation error codes json.\n",
      "        /// </summary>\n",
      "        /// <param name=\"previousErrors\">The previousErrors</param>\n",
      "        /// <param name=\"errorMessage\">The errorMessage</param>\n",
      "        /// <returns>Return validation error codes</returns>\n",
      "        public static string GetValidationErrorCodes(this string previousErrors, string errorMessage)\n",
      "        {\n",
      "            var listErrors = !string.IsNullOrEmpty(previousErrors) ? JsonConvert.DeserializeObject<List<string>>(previousErrors) : new List<string>();\n",
      "            listErrors.Add(errorMessage);\n",
      "            return JsonConvert.SerializeObject(listErrors);\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"../../cdcn/CDMS-CP Platform Core/SRC/Core.CoreFunctionHelpers/Helpers\"\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".cs\"):\n",
    "        file_path = f\"{path}\\{file}\"\n",
    "        with open(file_path, 'r') as f:\n",
    "            fileContent = f.read()\n",
    "            break\n",
    "print(fileContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance:\n",
      "- No performance issues found.\n",
      "\n",
      "Security:\n",
      "- No security issues found.\n",
      "\n",
      "Maintainability:\n",
      "- The code has poor naming conventions.\n",
      "- The code has no comments or documentation.\n",
      "- The namespace and using statements can be optimized.\n",
      "- The method name `GetValidationErrorCodes` is not descriptive.\n",
      "- The method parameter `previousErrors` is not descriptive.\n",
      "- The method parameter `errorMessage` is not descriptive.\n",
      "\n",
      "Severity:\n",
      "- Poor naming conventions, no comments/documentation, and namespace/using optimization have low severity.\n",
      "- Descriptive issues with method names and parameters have medium severity.\n"
     ]
    }
   ],
   "source": [
    "openai.api_version = os.getenv(\"OPENAI_EMBEDDING_VERSION\")\n",
    "prompt = \"You are a code review expert, good at finding code quality issues and suggesting alternatives.\\\n",
    "    Review the below code and summarize issues from a performance, security, and maintainability perspective. \\\n",
    "        Also, categorize the severity of the issue. Code:\"\n",
    "\n",
    "response = openai.ChatCompletion.create(    \n",
    "    temperature=0.7,\n",
    "    engine=\"gpt-35-turbo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt },\n",
    "        {\"role\": \"user\", \"content\": fileContent}\n",
    "    ], )\n",
    "  \n",
    "print(response['choices'][0]['message']['content'])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileContent}\n",
    "    ], )\n",
    "  \n",
    "print(response['choices'][0]['message']['content'])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance issue: \n",
      "The code does not appear to have any performance issues. \n",
      "\n",
      "Security issue: \n",
      "The code does not appear to have any security issues.\n",
      "\n",
      "Maintainability issue: \n",
      "The code does not include any descriptive comments for the GetValidationErrorCodes method, making it difficult for other developers to understand what the method does. \n",
      "\n",
      "Severity: Low\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(engine=\"text-davinci-003\", temperature=0.9)\n",
    "print(llm(prompt + fileContent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
